# Context Overflow Fix: Compact Mode for Multi-Film Queries

## Problem

After implementing detailed emotion interpretations, the RAG system hit a **context length limit** when analyzing multiple films:

```
Error code: 400 - This model's maximum context length is 16385 tokens.
However, your messages resulted in 37023 tokens (35759 in the messages, 1264 in the functions).
```

### Root Cause:

**Enhanced responses are much longer:**
- Full mode response: ~1000-1500 tokens per film (dialogue + emotions + interpretations)
- User query: "Is there any similarity on the emotion analysis for these movies?" (5 films)
- Total: 5 films Ã— 1500 tokens = **7,500 tokens just for tool responses**
- Add system prompt + chat history + function definitions = **37,023 tokens total**
- GPT-3.5-turbo limit: **16,385 tokens** âŒ

---

## Solution: Compact Mode

Added a `compact` parameter to `get_film_sentiment()` that returns abbreviated summaries for multi-film comparisons.

### Implementation

**File:** `src/ai/graph_query_tools.py`

**Function signature:**
```python
@tool
def get_film_sentiment(film_title: str, compact: bool = False) -> Dict[str, Any]:
```

**Compact mode output (55 tokens):**
```
**Spirited Away**: Overall sentiment 0.03 (neutral)
  ðŸŒŸ Peak: minute 103 (0.22)
  ðŸ˜” Valley: minute 80 (-0.18)
  Dominant emotion: caring (0.047)
```

**Full mode output (1000+ tokens):**
```
Spirited Away has an overall neutral sentiment (0.03).
Emotional peak occurs at minute 103.
Lowest point occurs at minute 80.

ðŸŒŸ Top positive moments:

1. **Minute 103** (sentiment: 0.22)
   **Key dialogue:**
   - "Where are you, baby!" (caring: 0.047, anger: 0.021)
   - "Come out, please!" (caring: 0.047, anger: 0.021)

   **Why this moment feels positive:**
   The dialogue here shows strong caring and anger emotions.
   Based on this emotional signature, I imagine this could be a moment of
   worried compassion - caring for someone who's suffering or in danger.

[... continues with 2 more positive peaks + 3 negative peaks]
```

---

## Technical Details

### Compact Mode Response Structure (lines 593-615):

```python
if compact:
    # COMPACT MODE: Brief summary for multi-film comparisons
    answer_parts = [
        f"**{exact_title}**: Overall sentiment {overall_sentiment:.2f} ({arc_direction})",
    ]

    # Show only top emotional peaks (no dialogue/interpretations)
    if positive_peaks:
        top_pos = positive_peaks[0]
        answer_parts.append(f"  ðŸŒŸ Peak: minute {top_pos['minute_offset']} ({top_pos['compound']:.2f})")

    if negative_peaks:
        top_neg = negative_peaks[0]
        answer_parts.append(f"  ðŸ˜” Valley: minute {top_neg['minute_offset']} ({top_neg['compound']:.2f})")

    # Get top emotion for characterization
    if dialogue_with_emotions and positive_peaks:
        peak_minute = positive_peaks[0]['minute_offset']
        peak_data = dialogue_with_emotions.get(peak_minute, {})
        peak_emotions = peak_data.get("emotions", {})
        if peak_emotions:
            top_emotion = max(peak_emotions.items(), key=lambda x: x[1])
            answer_parts.append(f"  Dominant emotion: {top_emotion[0]} ({top_emotion[1]:.3f})")
```

### Full Mode (else block, lines 617-698):

Existing detailed implementation with:
- Dialogue citations
- Emotion scores
- Interpretations for top 3 positive + top 3 negative moments

---

## System Prompt Guidance

**File:** `src/ai/rag_pipeline.py` (lines 474-479)

Added instruction for Sora:

```
**CRITICAL: Managing Context for Multi-Film Queries**
When analyzing 3+ films simultaneously, USE COMPACT MODE to prevent context overload:
- Call `get_film_sentiment(film_title, compact=True)` for multi-film comparisons
- Compact mode gives brief summaries (overall sentiment, top peak/valley, dominant emotion)
- After showing compact summaries, offer to deep-dive into any specific film
- Example: "I can provide detailed dialogue analysis for any of these films if you'd like!"
```

---

## Token Comparison

| Mode | Tokens per Film | 5 Films Total | Fits in Context? |
|------|-----------------|---------------|------------------|
| **Full** | ~1,500 | 7,500 | âŒ No (exceeds limit) |
| **Compact** | ~55 | 275 | âœ… Yes |

**Context budget breakdown (GPT-3.5-turbo, 16,385 token limit):**

- System prompt: ~1,200 tokens
- Function definitions: ~1,264 tokens
- Chat history (3 messages): ~500 tokens
- Tool responses (compact, 5 films): ~275 tokens
- LLM response generation: ~2,000 tokens
- **Total: ~5,239 tokens** âœ… Well within limit

---

## Usage Example

### User asks about similarities across multiple films:

**Query:** "Is there any similarity on the emotion analysis for The Tale of Princess Kaguya, Only Yesterday, Spirited Away, Grave of the Fireflies, and Arrietty?"

**Sora's response (using compact mode):**

```
Let me analyze the emotional patterns across these five critically acclaimed films:

**The Tale of the Princess Kaguya**: Overall sentiment 0.12 (positive)
  ðŸŒŸ Peak: minute 89 (0.45)
  ðŸ˜” Valley: minute 102 (-0.32)
  Dominant emotion: sadness (0.061)

**Only Yesterday**: Overall sentiment 0.08 (neutral)
  ðŸŒŸ Peak: minute 72 (0.38)
  ðŸ˜” Valley: minute 45 (-0.25)
  Dominant emotion: optimism (0.052)

**Spirited Away**: Overall sentiment 0.03 (neutral)
  ðŸŒŸ Peak: minute 103 (0.22)
  ðŸ˜” Valley: minute 80 (-0.18)
  Dominant emotion: caring (0.047)

**Grave of the Fireflies**: Overall sentiment -0.15 (negative)
  ðŸŒŸ Peak: minute 23 (0.18)
  ðŸ˜” Valley: minute 78 (-0.52)
  Dominant emotion: sadness (0.089)

**Arrietty**: Overall sentiment 0.11 (positive)
  ðŸŒŸ Peak: minute 67 (0.41)
  ðŸ˜” Valley: minute 34 (-0.19)
  Dominant emotion: fear (0.054)

**Patterns I notice:**

1. **Emotional balance**: Most films hover near neutral (0.03-0.12), except Grave of the Fireflies (-0.15) - notably the most tragic story
2. **Dominant emotions vary**: sadness (Kaguya, Fireflies), optimism (Only Yesterday), caring (Spirited Away), fear (Arrietty)
3. **Peak intensities**: Kaguya has the highest peak (0.45) and deepest valley (-0.32), suggesting the widest emotional range

Would you like me to provide detailed dialogue analysis for any of these films?
```

**Token cost:** ~800 tokens (well within budget)

---

## Benefits

1. **Prevents context overflow** - Can now analyze 5+ films simultaneously
2. **Fast responses** - Less data to process and transmit
3. **Still informative** - Shows sentiment, peaks, valleys, dominant emotion
4. **Offers deep-dive** - User can request full analysis on specific films

---

## Fallback Strategy

If Sora forgets to use compact mode and hits context limit again:

1. **Error handling** already exists in `rag_pipeline.py` (lines 981-988)
2. **User sees**: "âŒ Unexpected Error: An error occurred"
3. **Logs capture**: Full error with token counts
4. **Manual intervention**: User can ask "Tell me about just one film" to get full detail

---

## Testing

### Test compact mode:
```python
from src.ai.graph_query_tools import get_film_sentiment

# Compact
result = get_film_sentiment.func('Spirited Away', compact=True)
print(f"Tokens: {len(result['answer']) // 4}")  # ~55 tokens

# Full
result = get_film_sentiment.func('Spirited Away', compact=False)
print(f"Tokens: {len(result['answer']) // 4}")  # ~1000+ tokens
```

### Test via CLI:
```bash
./run_sora_cli.sh
>>> Tell me about the emotional similarities across Spirited Away, Princess Kaguya, and Grave of the Fireflies
```

**Expected:** Sora uses `compact=True` automatically for 3+ films

---

## Future Optimizations

If context issues persist:

1. **Reduce system prompt** - Currently ~1,200 tokens, could compress to ~800
2. **Summarize chat history** - Keep only last 2 exchanges instead of full history
3. **Lazy loading dialogue** - Only fetch dialogue when explicitly requested
4. **Upgrade to GPT-4** - Has 128K context window (but costs more)

---

## Files Modified

1. **`src/ai/graph_query_tools.py`**
   - Added `compact` parameter to `get_film_sentiment()` (line 418)
   - Added compact mode logic (lines 593-615)
   - Wrapped full mode in else block (lines 617-698)

2. **`src/ai/rag_pipeline.py`**
   - Added compact mode guidance to system prompt (lines 474-479)

---

## Summary

**Problem:** Enhanced interpretations made responses too long (37K tokens for 5 films)
**Solution:** Compact mode reduces response size by 95% (55 tokens vs 1500 tokens per film)
**Result:** Can now analyze 5+ films simultaneously without context overflow

The system intelligently switches between:
- **Compact mode** for multi-film comparisons (breadth)
- **Full mode** for single-film deep dives (depth)

This maintains the rich interpretive capabilities while respecting context limits.
